{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cmemsapi_functions.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNiygTkZ8FjM6xxRaMpahdC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mihhaila-ntnu-no/overboard_tracker/blob/main/cmemsapi_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01S66WriwXYA",
        "outputId": "ff30e023-96b7-40ab-81ea-3ba199d2a7d8"
      },
      "source": [
        "#! /usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"Main module.\"\"\"\n",
        "\n",
        "import calendar\n",
        "import datetime as dt\n",
        "import getpass as password\n",
        "import hashlib\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "from functools import reduce\n",
        "from importlib import reload\n",
        "from pathlib import Path\n",
        "\n",
        "import requests as rq\n",
        "import fire\n",
        "import lxml.html\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "from funcy import omit\n",
        "\n",
        "DEFAULT_CURRENT_PATH = os.getcwd()\n",
        "BOLD = '\\033[1m'\n",
        "END = '\\033[0m'\n",
        "LOGFILE = Path(\n",
        "    DEFAULT_CURRENT_PATH, 'log',\n",
        "    ''.join([\"CMEMS_API_\",\n",
        "             dt.datetime.now().strftime('%Y%m%d_%H%M'), \".log\"]))\n",
        "try:\n",
        "    if not LOGFILE.parent.exists():\n",
        "        LOGFILE.parent.mkdir(parents=True)\n",
        "    if os.path.exists(LOGFILE):\n",
        "        os.remove(LOGFILE)\n",
        "    print(f'[INFO] Logging to: {str(LOGFILE)}')\n",
        "    reload(logging)\n",
        "    logging.basicConfig(filename=LOGFILE,\n",
        "                        level=logging.DEBUG,\n",
        "                        format='[%(asctime)s] - [%(levelname)s] - %(message)s',\n",
        "                        datefmt='%Y-%m-%d %H:%M:%S')\n",
        "except IOError:\n",
        "    print(\"[ERROR] Failed to set logger.\")\n",
        "\n",
        "\n",
        "def set_target_directory(local_storage_directory=None):\n",
        "    \"\"\"\n",
        "    Returns working directory where data is saved.\n",
        "\n",
        "    Default value (None) creates a directory (``copernicus-tmp-data``)\n",
        "    in the current working directory.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    local_storage_directory : path or str, optional\n",
        "        A path object or string. The default is None.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    target_directory : path\n",
        "        A path to the directory where data is saved.\n",
        "\n",
        "    \"\"\"\n",
        "    if local_storage_directory:\n",
        "        target_directory = Path(local_storage_directory)\n",
        "    else:\n",
        "        target_directory = Path(DEFAULT_CURRENT_PATH, 'copernicus-tmp-data')\n",
        "    if not target_directory.exists():\n",
        "        target_directory.mkdir(parents=True)\n",
        "        print(f'[INFO] Directory successfully created : {target_directory}.')\n",
        "    return target_directory\n",
        "\n",
        "\n",
        "def multireplace(tobereplaced, substitute):\n",
        "    \"\"\"\n",
        "    Returns replaced string given string and substitute map.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tobereplaced : str\n",
        "        String to execute replacements on.\n",
        "    substitute : dict\n",
        "        Substitute dictionary {value to find: value to replace}.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        Replaced string.\n",
        "\n",
        "    \"\"\"\n",
        "    substrings = sorted(substitute, key=len, reverse=True)\n",
        "    regex = re.compile('|'.join(map(re.escape, substrings)))\n",
        "    return regex.sub(lambda match: substitute[match.group(0)], tobereplaced)\n",
        "\n",
        "\n",
        "def query(question, default=\"yes\"):\n",
        "    \"\"\"\n",
        "    Returns answer from a yes/no question, read from user\\'s input.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    question : str\n",
        "        String written as a question, displayed to user.\n",
        "    default : str, optional\n",
        "        String value to be presented to user to help . The default is \"yes\".\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    ValueError\n",
        "        Raise error to continue asking question until user inputs one of the valid choice.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    bool\n",
        "        Returns ``True`` if user validates question, ``False`` otherwise.\n",
        "\n",
        "    \"\"\"\n",
        "    valid = {\"yes\": True, \"y\": True, \"ye\": True, \"no\": False, \"n\": False}\n",
        "    if default is None:\n",
        "        prompt = \" [y/n] \"\n",
        "    elif default == \"yes\":\n",
        "        prompt = \" [Y/n] \"\n",
        "    elif default == \"no\":\n",
        "        prompt = \" [y/N] \"\n",
        "    else:\n",
        "        raise ValueError(f\"[ERROR] Invalid default answer: '{default}'\")\n",
        "    while True:\n",
        "        sys.stdout.write(question + prompt)\n",
        "        choice = input().lower()\n",
        "        if default is not None and choice == '':\n",
        "            return valid[default]\n",
        "        elif choice in valid:\n",
        "            return valid[choice]\n",
        "        else:\n",
        "            sys.stdout.write(\"[ACTION] Please respond with 'yes' or 'no' \"\n",
        "                             \"(or 'y' or 'n').\\n\")\n",
        "\n",
        "\n",
        "def get_config_constraints():\n",
        "    \"\"\"\n",
        "    Returns constraints configuration as ``dict`` from which data requests\n",
        "    will be stacked.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    split_dict : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    c_dict = {\n",
        "        'year': {\n",
        "            'depth': 6000,\n",
        "            'geo': 200\n",
        "        },\n",
        "        'month': {\n",
        "            'depth': 6000,\n",
        "            'geo': 360\n",
        "        },\n",
        "        'day': {\n",
        "            'depth': 6000,\n",
        "            'geo': 360\n",
        "        }\n",
        "    }\n",
        "\n",
        "    split_dict = {\n",
        "        'hourly_r': {\n",
        "            'pattern': [\n",
        "                '-hi', 'hourly', 'hts', 'fc-h', '1-027', '1-032', 'rean-h',\n",
        "                '1hr', '3dinst', '_hm', 'BLENDED', '15min', 'MetO-NWS-WAV-RAN',\n",
        "                'skin', 'surface'\n",
        "            ],\n",
        "            'year_s': c_dict['year'],\n",
        "            'month_s': c_dict['month'],\n",
        "            'day_s': c_dict['day']\n",
        "        },\n",
        "        'day_r': {\n",
        "            'pattern':\n",
        "            ['daily', 'weekly', 'an-fc-d', 'rean-d', 'day-', '-dm-'],\n",
        "            'year_s': c_dict['year'],\n",
        "            'month_s': c_dict['month'],\n",
        "            'day_s': c_dict['day']\n",
        "        },\n",
        "        'month_r': {\n",
        "            'pattern': [\n",
        "                'month', 'an-fc-m', 'rean-m', '-mm-', '-MON-',\n",
        "                'ran-arc-myoceanv2-be', 'CORIOLIS', 'bgc3d'\n",
        "            ],\n",
        "            'year_s': c_dict['year'],\n",
        "            'month_s': c_dict['month']\n",
        "        }\n",
        "    }\n",
        "    return split_dict\n",
        "\n",
        "\n",
        "def get_credentials(file_rc=None, sep='='):\n",
        "    \"\"\"\n",
        "    Returns Copernicus Marine Credentials.\n",
        "\n",
        "    Credentials can be specified in a file\n",
        "    or if ommitted, manually by user's input.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    file_rc : str or path, optional\n",
        "        Location of the file storing credentials. The default is None.\n",
        "    sep : str, optional\n",
        "        Character used to separate credential and its value. The default is `=`.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    SystemExit\n",
        "        Raise an error to exit program at fatal error (wrong credentials etc).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    copernicus_username : str\n",
        "        Copernicus Marine username.\n",
        "    copernicus_password : str\n",
        "        Copernicus Marine password.\n",
        "\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    if not file_rc:\n",
        "        file_rc = Path.cwd() / 'copernicus_credentials.txt'\n",
        "    try:\n",
        "        with open(file_rc, 'r') as cred:\n",
        "            for line in cred:\n",
        "                lines.append(line)\n",
        "    except FileNotFoundError:\n",
        "        print(f'[INFO] Credentials must be entered hereafter, obtained from: '\n",
        "              f'https://resources.marine.copernicus.eu/?option=com_sla')\n",
        "        print(\n",
        "            f'[INFO] If you have forgotten either your USERNAME '\n",
        "            f'(which {BOLD}is NOT your email address{END}) or your PASSWORD, '\n",
        "            f'please visit: https://marine.copernicus.eu/faq/forgotten-password/?idpage=169'\n",
        "        )\n",
        "        time.sleep(2)\n",
        "        usr = password.getpass(\n",
        "            prompt=f\"[ACTION] Please input your Copernicus {BOLD}USERNAME{END}\"\n",
        "            \" (and hit `Enter` key):\")\n",
        "        time.sleep(2)\n",
        "        pwd = password.getpass(\n",
        "            prompt=f\"[ACTION] Please input your Copernicus {BOLD}PASSWORD{END}\"\n",
        "            \" (and hit `Enter` key):\")\n",
        "        lines.append(f'username{sep}{usr}')\n",
        "        lines.append(f'password{sep}{pwd}')\n",
        "        create_cred_file = query(\n",
        "            f'[ACTION] For future usage, do you want to save credentials in a'\n",
        "            ' configuration file?', 'yes')\n",
        "        if create_cred_file:\n",
        "            with open(file_rc, 'w') as cred:\n",
        "                for line in lines:\n",
        "                    cred.write(''.join([line, '\\n']))\n",
        "    if not all([sep in item for item in lines]):\n",
        "        print('[ERROR] Sperator is not found. Must be specifed or corrected.\\n'\n",
        "              f'[WARNING] Please double check content of {file_rc}. '\n",
        "              f'It should match (please mind the `{sep}`):'\n",
        "              f'\\nusername{sep}<USERNAME>\\npassword{sep}<PASSWORD>')\n",
        "        raise SystemExit\n",
        "    copernicus_username = ''.join(lines[0].strip().split(sep)[1:])\n",
        "    copernicus_password = ''.join(lines[1].strip().split(sep)[1:])\n",
        "    if not check_credentials(copernicus_username, copernicus_password):\n",
        "        if file_rc.exists():\n",
        "            msg = f' from content of {file_rc}'\n",
        "        else:\n",
        "            msg = ''\n",
        "        print(\n",
        "            '[ERROR] Provided username and/or password could not be validated.\\n'\n",
        "            f'[WARNING] Please double check it{msg}. More help at: '\n",
        "            'https://marine.copernicus.eu/faq/forgotten-password/?idpage=169')\n",
        "        raise SystemExit\n",
        "    print('[INFO] Credentials have been succcessfully loaded and verified.')\n",
        "    return copernicus_username, copernicus_password\n",
        "\n",
        "\n",
        "def check_credentials(user, pwd):\n",
        "    \"\"\"\n",
        "    Check provided Copernicus Marine Credentials are correct.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    username : str\n",
        "        Copernicus Marine Username, provided for free from https://marine.copernicus.eu .\n",
        "    password : str\n",
        "        Copernicus Marine Password, provided for free from https://marine.copernicus.eu .\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    bool\n",
        "        Returns ``True`` if credentials are correst, ``False`` otherwise.\n",
        "\n",
        "    \"\"\"\n",
        "    cmems_cas_url = 'https://cmems-cas.cls.fr/cas/login'\n",
        "    conn_session = rq.session()\n",
        "    login_session = conn_session.get(cmems_cas_url)\n",
        "    login_from_html = lxml.html.fromstring(login_session.text)\n",
        "    hidden_elements_from_html = login_from_html.xpath(\n",
        "        '//form//input[@type=\"hidden\"]')\n",
        "    playload = {\n",
        "        he.attrib['name']: he.attrib['value']\n",
        "        for he in hidden_elements_from_html\n",
        "    }\n",
        "    playload['username'] = user\n",
        "    playload['password'] = pwd\n",
        "    conn_session.post(cmems_cas_url, data=playload)\n",
        "    if 'CASTGC' not in conn_session.cookies:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def get_viewscript():\n",
        "    \"\"\"\n",
        "    Ask the user to input the ``VIEW_SCRIPT`` command.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    view_myscript : str\n",
        "        String representing the ``TEMPLATE COMMAND`` generated by the\n",
        "        webportal. Example is available at https://tiny.cc/get-viewscript-from-web\n",
        "    \"\"\"\n",
        "    uni_test = [\n",
        "        'python -m motuclient --motu http', ' '.join([\n",
        "            '--out-dir <OUTPUT_DIRECTORY> --out-name <OUTPUT_FILENAME>',\n",
        "            '--user <USERNAME> --pwd <PASSWORD>'\n",
        "        ])\n",
        "    ]\n",
        "    while True:\n",
        "        view_myscript = input(\n",
        "            f\"[ACTION] Please paste the template command displayed on the webportal:\\n\"\n",
        "        )\n",
        "        if not all([item in view_myscript for item in uni_test]):\n",
        "            print(\n",
        "                '[ERROR] Cannot parse VIEWSCRIPT. '\n",
        "                'Please paste the ``TEMPLATE COMMAND`` as shown in this article: '\n",
        "                'https://marine.copernicus.eu/faq/'\n",
        "                'how-to-write-and-run-the-script-to-download-'\n",
        "                'cmems-products-through-subset-or-direct-download-mechanisms/?idpage=169'\n",
        "            )\n",
        "        else:\n",
        "            return view_myscript\n",
        "\n",
        "\n",
        "def viewscript_string_to_dict(viewmy_script):\n",
        "    \"\"\"\n",
        "    Convert the ``VIEW SCRIPT`` string displayed by the webportal to a ``dict``.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    viewmy_script : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    vs_dict : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    vs_dict = dict(\n",
        "        [e.strip().partition(\" \")[::2] for e in viewmy_script.split('--')])\n",
        "    vs_dict['variable'] = [value for (var, value) in [e.strip().partition(\" \")[::2] for e in viewmy_script.split('--')] if var == 'variable']  # pylint: disable=line-too-long\n",
        "    vs_dict['abs_geo'] = [\n",
        "        abs(float(vs_dict['longitude-min']) - float(vs_dict['longitude-max'])),\n",
        "        abs(float(vs_dict['latitude-min']) - float(vs_dict['latitude-max']))\n",
        "    ]\n",
        "    try:\n",
        "        vs_dict['abs_depth'] = abs(\n",
        "            float(vs_dict['depth-min']) - float(vs_dict['depth-max']))\n",
        "    except KeyError:\n",
        "        print(f\"[INFO] The {vs_dict['product-id']} is 3D and not 4D:\"\n",
        "              \" it does not contain depth dimension.\")\n",
        "    if len(vs_dict['date-min']) == 12:\n",
        "        dtformat = '%Y-%m-%d'\n",
        "    elif len(vs_dict['date-min']) > 12:\n",
        "        dtformat = '%Y-%m-%d %H:%M:%S'\n",
        "    vs_dict['dt-date-min'] = dt.datetime.strptime(vs_dict['date-min'][1:-1],\n",
        "                                                  dtformat)\n",
        "    vs_dict['dt-date-max'] = dt.datetime.strptime(vs_dict['date-max'][1:-1],\n",
        "                                                  dtformat)\n",
        "    if vs_dict['dt-date-max'].day == 1:\n",
        "        vs_dict['dt-date-max'] = vs_dict['dt-date-max'] + dt.timedelta(days=1)\n",
        "    vs_dict['delta-days'] = vs_dict['dt-date-max'] - vs_dict['dt-date-min']\n",
        "    vs_dict['prefix'] = '_'.join(\n",
        "        list((vs_dict['service-id'].split('-')[0]).split('_')[i]\n",
        "             for i in [0, -2, -1]))\n",
        "    vs_dict['suffix'] = '.nc'\n",
        "    if vs_dict['abs_geo'][0] == 0 and vs_dict['abs_geo'][1] == 0:\n",
        "        vs_dict['gridpoint'] = 'gridpoint'\n",
        "        if '-' in vs_dict['longitude-min']:\n",
        "            vs_dict['gridpoint'] = '_'.join([\n",
        "                vs_dict['gridpoint'],\n",
        "                vs_dict['longitude-min'].replace(\".\", \"dot\").replace(\"-\", \"W\")\n",
        "            ])\n",
        "        else:\n",
        "            vs_dict['gridpoint'] = '_'.join([\n",
        "                vs_dict['gridpoint'],\n",
        "                ''.join(['E', vs_dict['longitude-min'].replace('.', 'dot')])\n",
        "            ])\n",
        "        if '-' in vs_dict['latitude-min']:\n",
        "            vs_dict['gridpoint'] = '_'.join([\n",
        "                vs_dict['gridpoint'],\n",
        "                vs_dict['latitude-min'].replace(\".\", \"dot\").replace(\"-\", \"S\")\n",
        "            ])\n",
        "        else:\n",
        "            vs_dict['gridpoint'] = '_'.join([\n",
        "                vs_dict['gridpoint'],\n",
        "                ''.join(['N', vs_dict['latitude-min'].replace('.', 'dot')])\n",
        "            ])\n",
        "    if len(vs_dict['variable']) > 6:\n",
        "        vs_dict['out_var_name'] = 'several_vars'\n",
        "    else:\n",
        "        vs_dict['out_var_name'] = '_'.join(vs_dict['variable'])\n",
        "    return vs_dict\n",
        "\n",
        "\n",
        "def get_dates_stack(vs_dict, check_stack, size=None, renew=None):\n",
        "    \"\"\"\n",
        "    Update a ``dict`` containing ``VIEW SCRIPT`` values with dates for sub-requests.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    vs_dict : TYPE\n",
        "        DESCRIPTION.\n",
        "    check_stack : TYPE\n",
        "        DESCRIPTION.\n",
        "    size : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    renew : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    vs_dict : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    if not size:\n",
        "        cmd = 'cmd'\n",
        "    else:\n",
        "        cmd = 'size'\n",
        "    if not renew:\n",
        "        date_in = vs_dict['dt-date-min']\n",
        "    else:\n",
        "        date_in = renew\n",
        "    if check_stack == 'day':\n",
        "        vs_dict[f'{cmd}-date-min'] = dt.datetime(date_in.year, date_in.month,\n",
        "                                                 date_in.day, 0)\n",
        "        vs_dict[f'{cmd}-date-max'] = dt.datetime(date_in.year, date_in.month,\n",
        "                                                 date_in.day, 23, 30)\n",
        "        vs_dict['format'] = \"%Y%m%d\"\n",
        "    elif check_stack == 'month':\n",
        "        vs_dict[f'{cmd}-date-min'] = dt.datetime(date_in.year, date_in.month,\n",
        "                                                 1, 0)\n",
        "        vs_dict[f'{cmd}-date-max'] = dt.datetime(\n",
        "            date_in.year, date_in.month,\n",
        "            calendar.monthrange(date_in.year, date_in.month)[1], 23, 30)\n",
        "        vs_dict['format'] = \"%Y%m\"\n",
        "    elif check_stack == 'year':\n",
        "        if date_in.year == vs_dict['dt-date-max'].year:\n",
        "            vs_dict[f'{cmd}-date-max'] = dt.datetime(\n",
        "                date_in.year, vs_dict['dt-date-max'].month,\n",
        "                calendar.monthrange(date_in.year,\n",
        "                                    vs_dict['dt-date-max'].month)[1], 23, 30)\n",
        "        else:\n",
        "            vs_dict[f'{cmd}-date-max'] = dt.datetime(date_in.year, 12, 31, 23,\n",
        "                                                     30)\n",
        "        vs_dict[f'{cmd}-date-min'] = dt.datetime(date_in.year, date_in.month,\n",
        "                                                 date_in.day, 0)\n",
        "        vs_dict['format'] = \"%Y\"\n",
        "    else:\n",
        "        print(f'No matching stack queries found for: {check_stack}')\n",
        "    return vs_dict\n",
        "\n",
        "\n",
        "def viewscript_dict_to_string(size=None, strict=None, cmd=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Convert the ``dict`` containing keys and values of the ``VIEW SCRIPT``,\n",
        "    into a string as displayed by the webportal.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    size : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    strict : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    cmd : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    **kwargs : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    command : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    if size:\n",
        "        feature = 'size'\n",
        "    elif strict:\n",
        "        feature = 'dt'\n",
        "    elif cmd:\n",
        "        feature = 'cmd'\n",
        "    vs_string = []\n",
        "    if 'python' in kwargs:\n",
        "        vs_string.append(f\"python {kwargs['python']}\")\n",
        "    if 'motu' in kwargs:\n",
        "        vs_string.append(f\"--motu {kwargs['motu']}\")\n",
        "    if 'service-id' in kwargs:\n",
        "        vs_string.append(f\"--service-id {kwargs['service-id']}\")\n",
        "    if 'product-id' in kwargs:\n",
        "        vs_string.append(f\"--product-id {kwargs['product-id']}\")\n",
        "    if 'longitude-min' in kwargs:\n",
        "        vs_string.append(f\"--longitude-min {kwargs['longitude-min']}\")\n",
        "    if 'longitude-max' in kwargs:\n",
        "        vs_string.append(f\"--longitude-max {kwargs['longitude-max']}\")\n",
        "    if 'latitude-min' in kwargs:\n",
        "        vs_string.append(f\"--latitude-min {kwargs['latitude-min']}\")\n",
        "    if 'latitude-max' in kwargs:\n",
        "        vs_string.append(f\"--latitude-max {kwargs['latitude-max']}\")\n",
        "    if f'{feature}-date-min' in kwargs:\n",
        "        vs_string.append(f\"--date-min \\\"{kwargs[f'{feature}-date-min']}\\\"\")\n",
        "    if f'{feature}-date-max' in kwargs:\n",
        "        vs_string.append(f\"--date-max \\\"{kwargs[f'{feature}-date-max']}\\\"\")\n",
        "    if 'depth-min' in kwargs:\n",
        "        vs_string.append(f\"--depth-min {kwargs['depth-min']}\")\n",
        "    if 'depth-max' in kwargs:\n",
        "        vs_string.append(f\"--depth-max {kwargs['depth-max']}\")\n",
        "    if 'variable' in kwargs:\n",
        "        #if type(kwargs['variable']) == list:\n",
        "        if isinstance(kwargs['variable'], list):\n",
        "            for var in kwargs['variable']:\n",
        "                vs_string.append(f\"--variable {var}\")\n",
        "            # re-written due to pylint #3397\n",
        "            #[vs_string.append(f\"--variable {var}\") for var in kwargs['variable']]\n",
        "        else:\n",
        "            vs_string.append(f\"--variable {kwargs['variable']}\")\n",
        "    if 'outname' in kwargs:\n",
        "        vs_string.append(f\"--out-name {kwargs['outname']}\")\n",
        "    if 'target_directory' in kwargs:\n",
        "        vs_string.append(f\"--out-dir {kwargs['target_directory']}\")\n",
        "    command = ' '.join(vs_string)\n",
        "    return command\n",
        "\n",
        "\n",
        "def get_data(command=None, user=None, pwd=None, size=None):\n",
        "    \"\"\"\n",
        "    Returns status of binary netCDF file or, if ``size`` is specified,\n",
        "    potential result file size, whose units is `kBytes`.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    command : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    user : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    pwd : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    size : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    returncode : TYPE\n",
        "        DESCRIPTION.\n",
        "    message : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    if not user and not pwd:\n",
        "        user, pwd = get_credentials()\n",
        "    if not command:\n",
        "        view_myscript = get_viewscript()\n",
        "        command = view_myscript.replace(\n",
        "            '--out-dir <OUTPUT_DIRECTORY> --out-name <OUTPUT_FILENAME> '\n",
        "            '--user <USERNAME> --pwd <PASSWORD>', '')\n",
        "    msg = ''\n",
        "    if size:\n",
        "        msg = '--size -o console'\n",
        "    get_command = ' '.join([command, msg, '-q -u ', user, ' -p ', pwd])\n",
        "    cmd_rep = get_command.replace(get_command.split(' ')[-1], '****')\n",
        "    logging.info(\"SUBMIT REQUEST: %s\", cmd_rep)\n",
        "    process = subprocess.Popen(get_command,\n",
        "                               stdout=subprocess.PIPE,\n",
        "                               stderr=subprocess.PIPE,\n",
        "                               shell=True)\n",
        "    message, _ = process.communicate()\n",
        "    returncode = process.returncode\n",
        "    return returncode, message\n",
        "\n",
        "\n",
        "def check_data(returncode,\n",
        "               message,\n",
        "               command=None,\n",
        "               user=None,\n",
        "               stack=None,\n",
        "               size=None):\n",
        "    \"\"\"\n",
        "    Returns ``True`` if status of the submitted request is successful,\n",
        "    ``False`` otherwise.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    returncode : TYPE\n",
        "        DESCRIPTION.\n",
        "    message : TYPE\n",
        "        DESCRIPTION.\n",
        "    command : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    user : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    stack : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    size : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    SystemExit\n",
        "        Raise an error to exit program at fatal error due to server maintenance.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    valid_check : bool\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    valid_check = False\n",
        "    if returncode == 0:\n",
        "        if b'[ERROR]' in message:\n",
        "            logging.error(\"FAILED REQUEST - raised error:\\n %s\", message)\n",
        "        else:\n",
        "            if size:\n",
        "                if stack:\n",
        "                    if b'code=\"005-0\"' in message:\n",
        "                        valid_check = True\n",
        "                elif b'code=\"005-0\"' not in message and b'code=\"005-7\"' in message:\n",
        "                    # Handling exceptions due to changes in MOTU API from v3.10 to v3.12\n",
        "                    try:\n",
        "                        req_size = convert_size_hr(\n",
        "                            (float(str(message).split('=')[-1].split('\"')[1])) *\n",
        "                            1000)\n",
        "                    except ValueError:\n",
        "                        req_size = convert_size_hr(\n",
        "                            (float(str(message).split('=')[4].split('\"')[1])) *\n",
        "                            1000)\n",
        "                    treshold_size = convert_size_hr(1.0E8 * 1000)\n",
        "                    if req_size > treshold_size:\n",
        "                        token = hashlib.md5(\n",
        "                            (':'.join([command.rstrip(),\n",
        "                                       user])).encode('utf-8')).hexdigest()\n",
        "                        token_url = 'https://github.com/copernicusmarine/cmemsapi/blob/master/_transactions' # pylint: disable=line-too-long\n",
        "                        resp = rq.get(f'{token_url}/{token}')\n",
        "                        if resp.status_code == 200:\n",
        "                            valid_check = True\n",
        "                        else:\n",
        "                            msg = (\n",
        "                                '[ERROR] Your datarequest exceeds max limit set to 100 GiB.\\n'\n",
        "                                '[ACTION] Please contact Support Team at:\\n'\n",
        "                                '         https://marine.copernicus.eu/services-portfolio/contact-us/ \\n' # pylint: disable=line-too-long\n",
        "                                f'[ACTION] And submit a query attaching your logile located here:\\n'\n",
        "                                f'         {LOGFILE}.\\n'\n",
        "                                '[INFO] Once it is done and by the next 48 hours, '\n",
        "                                'the Support Team will authorize your request '\n",
        "                                'and send an email to the inbox linked to '\n",
        "                                f'the Copernicus Marine Account (username = {user}) '\n",
        "                                'for confirmation and instructions.'\n",
        "                            )\n",
        "                            print(msg)\n",
        "                            logging.error(msg)\n",
        "                    else:\n",
        "                        valid_check = True\n",
        "                elif b'code=\"005-0\"' in message:\n",
        "                    valid_check = True\n",
        "            else:\n",
        "                logging.info('Request status is successful')\n",
        "                print(\n",
        "                    '[INFO] Server is releasing the token to successfully grant next request. '\n",
        "                    'It will resume AUTOMATICALLY.\\n')\n",
        "                time.sleep(5)\n",
        "                valid_check = True\n",
        "    else:\n",
        "        logging.error(\"FAILED REQUEST - raised error:\\n %s\", message)\n",
        "        print('[WARNING] Failed data request has been logged.\\n')\n",
        "        if b'HTTP Error 503' in message:\n",
        "            print(\n",
        "                'HTTP Error 503 - Service is temporary down. Break for 5 minutes.'\n",
        "            )\n",
        "            time.sleep(300)\n",
        "        if b'HTTP Error 4' in message:\n",
        "            logging.error('Permanent error. Exiting program.')\n",
        "            raise SystemExit\n",
        "    return valid_check\n",
        "\n",
        "\n",
        "def process_viewscript(target_directory,\n",
        "                       view_myscript=None,\n",
        "                       user=None,\n",
        "                       pwd=None,\n",
        "                       forcestack=None):\n",
        "    \"\"\"\n",
        "    Generates as many data requests as required to match initial ``VIEW_SCRIPT``.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    target_directory : str or path\n",
        "        DESCRIPTION.\n",
        "    view_myscript : str, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    user : str, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    pwd : str, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    forcestack : bool, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    ValueError\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    TYPE\n",
        "        On success, returns path of the output file matching the\n",
        "        ``VIEW_SCRIPT`` data request, ``False`` otherwise.\n",
        "\n",
        "    \"\"\"\n",
        "    split_dict = get_config_constraints()\n",
        "    outname = False\n",
        "    if not user and not pwd:\n",
        "        user, pwd = get_credentials()\n",
        "    if not view_myscript:\n",
        "        view_myscript = get_viewscript()\n",
        "    else:\n",
        "        uni_test = [\n",
        "            'python -m motuclient --motu http', ' '.join([\n",
        "                '--out-dir <OUTPUT_DIRECTORY> --out-name <OUTPUT_FILENAME>',\n",
        "                '--user <USERNAME> --pwd <PASSWORD>'\n",
        "            ])\n",
        "        ]\n",
        "        if not all([item in view_myscript for item in uni_test]):\n",
        "            msg = (\n",
        "                '[DEBUG] Cannot parse VIEWSCRIPT. '\n",
        "                'Please paste the ``TEMPLATE COMMAND`` as shown in this article: '\n",
        "                'https://marine.copernicus.eu/faq/'\n",
        "                'how-to-write-and-run-the-script-to-download-'\n",
        "                'cmems-products-through-subset-or-direct-download-mechanisms/?idpage=169'\n",
        "            )\n",
        "            raise ValueError(msg)\n",
        "    view_script_command = view_myscript.replace(\n",
        "        '--out-dir <OUTPUT_DIRECTORY> --out-name <OUTPUT_FILENAME> '\n",
        "        '--user <USERNAME> --pwd <PASSWORD>', '')\n",
        "    init_returncode, init_message = get_data(view_script_command,\n",
        "                                             user,\n",
        "                                             pwd,\n",
        "                                             size=True)\n",
        "    if not check_data(\n",
        "            init_returncode, init_message, view_script_command, user,\n",
        "            size=True):\n",
        "        return outname\n",
        "    vs_dict = viewscript_string_to_dict(view_script_command)\n",
        "    vs_dict['target_directory'] = str(target_directory)\n",
        "    if not forcestack:\n",
        "        for key_r, val_r in split_dict.items():\n",
        "            if any(x in vs_dict['product-id']\n",
        "                   for x in val_r.get('pattern', 'Not Found')):\n",
        "                for key_s, val_s in omit(split_dict[key_r].items(), 'pattern'):\n",
        "                    try:\n",
        "                        check = all([\n",
        "                            val_s.get('depth') >= vs_dict['abs_depth'],\n",
        "                            *([g <= val_s.get('geo') for g in vs_dict['abs_geo']])\n",
        "                        ])\n",
        "                    except KeyError:\n",
        "                        check = all([\n",
        "                            *([g <= val_s.get('geo') for g in vs_dict['abs_geo']])\n",
        "                        ])\n",
        "                    if check:\n",
        "                        check_stack = key_s[:-2]\n",
        "                        if vs_dict['delta-days'].days < 28:\n",
        "                            check_stack = 'day'\n",
        "                        vs_dict = get_dates_stack(vs_dict,\n",
        "                                                  check_stack,\n",
        "                                                  size=True)\n",
        "                        command_size = viewscript_dict_to_string(size=True,\n",
        "                                                                 **vs_dict)\n",
        "                        returncode, message = get_data(command_size,\n",
        "                                                       user,\n",
        "                                                       pwd,\n",
        "                                                       size=True)\n",
        "                        if check_data(returncode,\n",
        "                                      message,\n",
        "                                      stack=check_stack,\n",
        "                                      size=True):\n",
        "                            stack = check_stack\n",
        "                            break\n",
        "    else:\n",
        "        stack = forcestack\n",
        "    try:\n",
        "        msg = (f'[INFO] Data requests will be submitted by '\n",
        "               f'{stack} stacks.')\n",
        "    except NameError:\n",
        "        stack = 'day'\n",
        "        msg = ('[WARNING] No matching temporal resolution. '\n",
        "               f'To be coded using CSW. Stack is set to {stack}.')\n",
        "    print(msg)\n",
        "    print('\\n+------------------------------------+\\n| ! - CONNECTION TO CMEMS'\n",
        "          'HUB - OPEN |\\n+------------------------------------+\\n\\n')\n",
        "    for retry in range(1, 4):\n",
        "        retry_flag = False\n",
        "        date_start = vs_dict['dt-date-min']\n",
        "        date_end = vs_dict['dt-date-max']\n",
        "        vs_dict = get_dates_stack(vs_dict, stack)\n",
        "        while date_start <= date_end:\n",
        "            date_end_format = vs_dict['cmd-date-max'].strftime(\n",
        "                vs_dict['format'])\n",
        "            try:\n",
        "                vs_dict['outname'] = '-'.join([\n",
        "                    'CMEMS', vs_dict['prefix'], vs_dict['gridpoint'],\n",
        "                    vs_dict['out_var_name'],\n",
        "                    date_end_format + vs_dict['suffix']\n",
        "                ])\n",
        "            except KeyError:\n",
        "                vs_dict['outname'] = '-'.join([\n",
        "                    'CMEMS', vs_dict['prefix'], vs_dict['out_var_name'],\n",
        "                    date_end_format + vs_dict['suffix']\n",
        "                ])\n",
        "            command = viewscript_dict_to_string(cmd=True, **vs_dict)\n",
        "            outname = vs_dict['outname']\n",
        "            print(\n",
        "                '\\n----------------------------------\\n'\n",
        "                '- ! - Processing dataset request : '\n",
        "                f\"{outname}\\n----------------------------------\\n\")\n",
        "            if not Path(target_directory / outname).exists():\n",
        "                print('## MOTU API COMMAND ##')\n",
        "                print(command.replace(user, '*****').replace(pwd, '*****'))\n",
        "                print(\n",
        "                    '\\n[INFO] New data request has been submitted to Copernicus'\n",
        "                    'Marine Servers. '\n",
        "                    'If successful, it will extract the data and create your'\n",
        "                    ' dataset on the fly. Please wait. \\n')\n",
        "                returncode, message = get_data(command, user, pwd)\n",
        "                if check_data(returncode, message):\n",
        "                    print('[INFO] The dataset for {} has been stored in {}.'.\n",
        "                          format(outname, target_directory))\n",
        "                else:\n",
        "                    retry_flag = True\n",
        "            else:\n",
        "                print(f\"[INFO] The dataset for {outname} \"\n",
        "                      f\"has already been downloaded in {target_directory}\\n\")\n",
        "            date_start = vs_dict['cmd-date-max'] + dt.timedelta(days=1)\n",
        "            vs_dict = get_dates_stack(vs_dict, stack, renew=date_start)\n",
        "        if not retry_flag:\n",
        "            break\n",
        "    print(\"+-------------------------------------+\\n| ! - CONNECTION TO CMEMS \"\n",
        "          \"HUB - CLOSE |\\n+-------------------------------------+\\n\")\n",
        "    with open(LOGFILE) as logfile:\n",
        "        if retry == 3 and 'ERROR' in logfile.read():\n",
        "            print(\"## YOUR ATTENTION IS REQUIRED ##\")\n",
        "            print(f'Some download requests failed, though {retry} retries. '\n",
        "                  f'Please see recommendation in {LOGFILE})')\n",
        "            print('TIPS: you can also apply hereafter recommendations.'\n",
        "                  '\\n1.  Do not move netCDF files'\n",
        "                  '\\n2.  Double check if a change must be done in the '\n",
        "                  'viewscript, FTR it is currently set to:\\n')\n",
        "            print(view_myscript)\n",
        "            print(\n",
        "                '\\n3.  Check there is not an ongoing maintenance by looking '\n",
        "                'at the User Notification Service and Systems & Products Status:\\n',\n",
        "                'https://marine.copernicus.eu/services-portfolio/news-flash/'\n",
        "                '\\n4.  Then, if relevant, do relaunch manually this python '\n",
        "                'script to automatically download only failed data request(s)'\n",
        "                '\\n5.  Finally, feel free to contact our Support Team either:'\n",
        "                '\\n  - By mail: servicedesk.cmems@mercator-ocean.eu or \\n  - '\n",
        "                'By using the webform: '\n",
        "                'https://marine.copernicus.eu/services-portfolio/contact-us/'\n",
        "                ' or \\n  - By leaving a post on the forum:'\n",
        "                ' https://forum.marine.copernicus.eu\\n\\n')\n",
        "            outname = False\n",
        "    return outname\n",
        "\n",
        "\n",
        "def convert_size_hr(size_in_bytes):\n",
        "    \"\"\"\n",
        "    Get size from bytes and displays to user in human readable.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    size_in_bytes : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    if size_in_bytes == 0:\n",
        "        return '0 Byte'\n",
        "    size_standard = ('B', 'KiB', 'MiB', 'GiB', 'TiB')\n",
        "    integer = int(math.floor(math.log(size_in_bytes, 1_024)))\n",
        "    powmath = math.pow(1_024, integer)\n",
        "    precision = 2\n",
        "    size = round(size_in_bytes / powmath, precision)\n",
        "    return size, size_standard[integer]\n",
        "\n",
        "\n",
        "def get_disk_stat(drive=None):\n",
        "    \"\"\"\n",
        "    Get disk size statistics.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    drive : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    disk_stat : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    if not drive:\n",
        "        drive = '/'\n",
        "    disk_stat = list(shutil.disk_usage(drive))\n",
        "    return disk_stat\n",
        "\n",
        "\n",
        "def get_file_size(files):\n",
        "    \"\"\"\n",
        "    Get size of file(s) in bytes.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    files : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    mds_size : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    mds_size = 0\n",
        "    for file in files:\n",
        "        with xr.open_dataset(file, decode_cf=False) as sds:\n",
        "            mds_size = mds_size + sds.nbytes\n",
        "    return mds_size\n",
        "\n",
        "\n",
        "def check_file_size(mds_size, default_nc_size=None):\n",
        "    \"\"\"\n",
        "    Check size of file(s).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mds_size : TYPE\n",
        "        DESCRIPTION.\n",
        "    default_nc_size : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    check_fs : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    if not default_nc_size:\n",
        "        default_nc_size = 16_000_000_000\n",
        "    check_fs = False\n",
        "    size, unit = display_disk_stat(mds_size)\n",
        "    if mds_size == 0:\n",
        "        print(f'[ERROR-NETCDF] There is an error to assess the size of netCDF '\n",
        "              'file(s). Please check if data are not corrupted.')\n",
        "    elif size == 0:\n",
        "        print(f'[ERROR] Program exit.')\n",
        "    elif mds_size > default_nc_size:\n",
        "        print(f'[INFO-NETCDF] The size of the netCDF file would be higher than'\n",
        "              ' 16 GiB.')\n",
        "        force = query(\n",
        "            f'[ACTION-NETCDF] Do you still want to create the netCDF file of '\n",
        "            f'{BOLD}size {size} {unit}{END}?', 'no')\n",
        "        if not force:\n",
        "            print('[ERROR-NETCDF] Writing to disk action has been aborted by '\n",
        "                  'user due to file size issue.')\n",
        "            print('[INFO-NETCDF] The script will try to write several netCDF '\n",
        "                  'files with lower file size.')\n",
        "        else:\n",
        "            check_fs = True\n",
        "    else:\n",
        "        check_fs = True\n",
        "    return check_fs\n",
        "\n",
        "\n",
        "def display_disk_stat(mds_size):\n",
        "    \"\"\"\n",
        "    Display hard drive statistics to user.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mds_size : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    mds_size_hr : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    disk_stat = get_disk_stat()\n",
        "    free_after = disk_stat[2] - mds_size\n",
        "    disk_stat.append(free_after)\n",
        "    disk_stat.append(mds_size)\n",
        "    try:\n",
        "        total_hr, used_hr, free_hr, free_after_hr, mds_size_hr = [\n",
        "            convert_size_hr(item) for item in disk_stat\n",
        "        ]\n",
        "    except ValueError as error:\n",
        "        msg = f\"[WARNING] Operation shall be aborted to avoid NO SPACE LEFT ON\\\n",
        "             DEVICE error: {error}\"\n",
        "\n",
        "        mds_size_hr = (0, 'B')\n",
        "    else:\n",
        "        space = '-' * 37\n",
        "        msg = ''.join(\n",
        "            (f\"[INFO] {space}\\n\",\n",
        "             f\"[INFO] Total Disk Space (before operation) :\"\n",
        "             f\" {total_hr[1]} {total_hr[0]} \\n\",\n",
        "             f\"[INFO] Used Disk Space (before operation)  :\"\n",
        "             f\" {used_hr[1]} {used_hr[0]} \\n\",\n",
        "             f\"[INFO] Free Disk Space (before operation)  :\"\n",
        "             f\" {free_hr[1]} {free_hr[0]} \\n\",\n",
        "             f\"[INFO] Operation to save dataset to Disk   :\"\n",
        "             f\" {mds_size_hr[1]} {mds_size_hr[0]} \\n\",\n",
        "             f\"[INFO] Free Disk Space (after operation)   :\"\n",
        "             f\" {free_after_hr[1]} {free_after_hr[0]} \\n\", f\"[INFO] {space}\"))\n",
        "    print(''.join((\"[INFO] CHECK DISK STATISTICS\\n\", msg)))\n",
        "    return mds_size_hr\n",
        "\n",
        "\n",
        "def get_file_pattern(outname, sep='-', rem=-1, advanced=True):\n",
        "    \"\"\"\n",
        "    Retrieve a ``file_pattern`` from a filename and advanced regex.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    outname : str\n",
        "        Filename from which a pattern must be extracted.\n",
        "    sep : str, optional\n",
        "        Separator. The default is '-'.\n",
        "    rem : TYPE, optional\n",
        "        Removal parts. The default is -1.\n",
        "    advanced : TYPE, optional\n",
        "        Advanced regex. The default is True.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    file_pattern : str\n",
        "        The ``file_pattern`` extracted from ``filename``.\n",
        "\n",
        "    \"\"\"\n",
        "    if 'pathlib' in str(type(outname)):\n",
        "        outname = outname.name\n",
        "    if advanced:\n",
        "        file_pattern = outname.replace(outname.split(sep)[rem], '')[:-1]\n",
        "    else:\n",
        "        # To be coded\n",
        "        pass\n",
        "    return file_pattern\n",
        "\n",
        "\n",
        "def get_years(ncfiles, sep='-'):\n",
        "    \"\"\"\n",
        "    Retrieve a list of years from a list of netCDF filenames.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ncfiles : list\n",
        "        List of filenames from which years will be extracted.\n",
        "    sep : TYPE, optional\n",
        "        Separator. The default is '-'.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    years : set\n",
        "        List of years.\n",
        "\n",
        "    \"\"\"\n",
        "    years = set([str(f).split(sep)[-1][:4] for f in ncfiles])\n",
        "    return years\n",
        "\n",
        "\n",
        "def get_ncfiles(target_directory, file_pattern=None, year=None):\n",
        "    \"\"\"\n",
        "    Retrieve list of files, based on parameters.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    target_directory : str\n",
        "        DESCRIPTION.\n",
        "    file_pattern : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    year : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ncfiles : list\n",
        "        List of strings containing absolute path to files.\n",
        "\n",
        "    \"\"\"\n",
        "    if 'str' in str(type(target_directory)):\n",
        "        target_directory = Path(target_directory)\n",
        "    if file_pattern and year:\n",
        "        ncfiles = list(target_directory.glob(f'{file_pattern}*{year}*.nc'))\n",
        "    elif file_pattern and not year:\n",
        "        ncfiles = list(target_directory.glob(f'*{file_pattern}*.nc'))\n",
        "    elif year and not file_pattern:\n",
        "        ncfiles = list(target_directory.glob(f'*{year}*.nc'))\n",
        "    else:\n",
        "        ncfiles = list(target_directory.glob('*.nc'))\n",
        "    return ncfiles\n",
        "\n",
        "\n",
        "def set_outputfile(file_pattern,\n",
        "                   target_directory,\n",
        "                   target_out_directory=None,\n",
        "                   start_year=None,\n",
        "                   end_year=None):\n",
        "    \"\"\"\n",
        "    Set output filename based on variables.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    file_pattern : TYPE\n",
        "        DESCRIPTION.\n",
        "    target_directory : TYPE\n",
        "        DESCRIPTION.\n",
        "    target_out_directory : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    start_year : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    end_year : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    outputfile : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    if not target_out_directory:\n",
        "        target_out_directory = Path(target_directory.parent,\n",
        "                                    'copernicus-processed-data')\n",
        "    elif 'str' in str(type(target_out_directory)):\n",
        "        target_out_directory = Path(target_out_directory)\n",
        "    if not target_out_directory.exists():\n",
        "        target_out_directory.mkdir(parents=True)\n",
        "    if start_year == end_year or not end_year:\n",
        "        outputfile = target_out_directory / f'{file_pattern}-{start_year}.nc'\n",
        "    else:\n",
        "        outputfile = target_out_directory / \\\n",
        "            f'{file_pattern}-{start_year}_{end_year}.nc'\n",
        "    return outputfile\n",
        "\n",
        "\n",
        "def over_write(outputfile):\n",
        "    \"\"\"\n",
        "    Ask user if overwrite action should be performed.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    outputfile : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ow : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    ok_overwrite = True\n",
        "    if outputfile.exists():\n",
        "        ok_overwrite = query(\n",
        "            f'[ACTION] The file {outputfile} already exists. Do you want '\n",
        "            f'{BOLD}to overwrite{END} it?', 'no')\n",
        "    return ok_overwrite\n",
        "\n",
        "\n",
        "def del_ncfiles(ncfiles):\n",
        "    \"\"\"\n",
        "    Delete files.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ncfiles : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    bool\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    for fnc in ncfiles:\n",
        "        try:\n",
        "            fnc.unlink()\n",
        "        except OSError as error:\n",
        "            print(f'[ERROR]: {fnc} : {error.strerror}')\n",
        "    print(\n",
        "        '[INFO-NETCDF] All inputs netCDF files have been successfully deleted.'\n",
        "    )\n",
        "    return True\n",
        "\n",
        "\n",
        "def to_nc4(mds, outputfile):\n",
        "    \"\"\"\n",
        "    Convert file(s) to one single netCDF-4 file, based on computer limits.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mds : TYPE\n",
        "        DESCRIPTION.\n",
        "    outputfile : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    nc4 : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    if 'xarray.core.dataset.Dataset' not in str(type(mds)):\n",
        "        mds = xr.open_mfdataset(mds, combine='by_coords')\n",
        "    if 'str' in str(type(outputfile)):\n",
        "        outputfile = Path(outputfile)\n",
        "    prepare_encoding = {}\n",
        "    for variable in mds.data_vars:\n",
        "        prepare_encoding[variable] = mds[variable].encoding\n",
        "        prepare_encoding[variable]['zlib'] = True\n",
        "        prepare_encoding[variable]['complevel'] = 1\n",
        "    encoding = {}\n",
        "    for key_encod, var_encod in prepare_encoding.items():\n",
        "        encoding.update({\n",
        "            key_encod: {\n",
        "                key: value\n",
        "                for key, value in var_encod.items() if key != 'coordinates'\n",
        "            }\n",
        "        })\n",
        "    try:\n",
        "        mds.to_netcdf(path=outputfile,\n",
        "                      mode='w',\n",
        "                      engine='netcdf4',\n",
        "                      encoding=encoding)\n",
        "    except ValueError as error:\n",
        "        print(\n",
        "            f'[INFO-NETCDF] Convertion initialized but ended in error due to : {error}'\n",
        "        )\n",
        "        nc4 = False\n",
        "    else:\n",
        "        real_file_size = convert_size_hr(outputfile.stat().st_size)\n",
        "        space = '-' * 20\n",
        "        msg = ''.join((f\"[INFO] {space}\\n\", f\"[INFO-NETCDF] Output file :\"\n",
        "                       f\" {str(outputfile)}\\n\",\n",
        "                       f\"[INFO-NETCDF] File format : netCDF-4\\n\",\n",
        "                       f\"[INFO-NETCDF] File size   : {real_file_size[0]}\"\n",
        "                       f\" {real_file_size[1]}\\n\", f\"[INFO] {space}\"))\n",
        "        print(''.join((\"[INFO] CONVERTING TO NETCDF4\\n\", msg)))\n",
        "        nc4 = True\n",
        "    return nc4\n",
        "\n",
        "\n",
        "def to_csv(mds, outputfile):\n",
        "    \"\"\"\n",
        "    Convert file(s) to one single csv file, based on computer limits.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mds : TYPE\n",
        "        DESCRIPTION.\n",
        "    outputfile : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    csv : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    if 'xarray.core.dataset.Dataset' not in str(type(mds)):\n",
        "        mds = xr.open_mfdataset(mds, combine='by_coords')\n",
        "    if 'str' in str(type(outputfile)):\n",
        "        outputfile = Path(outputfile)\n",
        "    msg2 = 'please contact support at: https://marine.copernicus.eu/services-portfolio/contact-us/'\n",
        "    csv = False\n",
        "    force = False\n",
        "    ms_excel_row_limit = 1_048_576\n",
        "    nb_grid_pts = reduce((lambda x, y: x * y),\n",
        "                         list([len(mds[c]) for c in mds.coords]))\n",
        "    if nb_grid_pts > ms_excel_row_limit:\n",
        "        print(f'[INFO-CSV] The total number of rows exceeds MS Excel limit.'\n",
        "              f' It is {BOLD}NOT recommended{END} to continue.')\n",
        "        force = query(\n",
        "            f'[ACTION-CSV] Do you still want to create this CSV file with'\n",
        "            f' {BOLD}{nb_grid_pts} rows{END} (though most computers will run out of memory)?',\n",
        "            'no')\n",
        "    if nb_grid_pts < ms_excel_row_limit or force:\n",
        "        try:\n",
        "            dataframe = mds.to_dataframe().reset_index().dropna()\n",
        "            outputfile = outputfile.with_suffix('.csv')\n",
        "            dataframe.to_csv(outputfile, index=False)\n",
        "        except IOError:\n",
        "            print(f'[INFO-CSV] Convertion initialized but ended in error.')\n",
        "        else:\n",
        "            space = '-' * 18\n",
        "            msg = ''.join(\n",
        "                (f\"[INFO] {space}\\n\", f\"[INFO-CSV] Output file :\"\n",
        "                 f\" {str(outputfile)}\\n\",\n",
        "                 f\"[INFO-CSV] File format : Comma-Separated Values\\n\",\n",
        "                 f\"[INFO-CSV] Preview Stat:\\n {dataframe.describe()}\\n\",\n",
        "                 f\"[INFO] {space}\"))\n",
        "            print(''.join((\"[INFO] CONVERTING TO CSV\\n\", msg)))\n",
        "            csv = True\n",
        "    else:\n",
        "        print('[WARNING-CSV] Writing to disk action has been aborted by user '\n",
        "              f'due to very high number of rows ({nb_grid_pts}) exceeding most '\n",
        "              'computers and softwares limits (such as MS Excel).')\n",
        "        print(' '.join(\n",
        "            ('[INFO-CSV] A new function is under beta-version to handle '\n",
        "             'this use case automatically.\\n'\n",
        "             '[ACTION-CSV] Usage:\\n'\n",
        "             'cmemstb to_mfcsv PATH_TO_NETCDF_DIRECTORY PATH_TO_OUTPUT_DIRECTORY\\n'\n",
        "             '[INFO-CSV] To upvote this feature,',\n",
        "             msg2)))\n",
        "    try:\n",
        "        mds.close()\n",
        "        del mds\n",
        "    except NameError:\n",
        "        print(''.join(('[DEBUG] ', msg2)))\n",
        "    return csv\n",
        "\n",
        "\n",
        "def to_mfcsv(input_directory, output_directory, max_depth_level=None):\n",
        "    \"\"\"\n",
        "    Convert netcdf file(s) to multiple csv files, based on MS Excel Limits.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_directory : TYPE\n",
        "        DESCRIPTION.\n",
        "    output_directory : TYPE\n",
        "        DESCRIPTION.\n",
        "    max_depth_level : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    mfcsv : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    mfcsv = False\n",
        "    if isinstance(input_directory, xr.Dataset):\n",
        "        mds = input_directory\n",
        "    else:\n",
        "        try:\n",
        "            # Either a string glob in the form \"path/to/my/files/*.nc\"\n",
        "            # or an explicit list of files to open.\n",
        "            mds = xr.open_mfdataset(input_directory, combine='by_coords')\n",
        "        except Exception:\n",
        "            input_directory = Path(input_directory)\n",
        "            mds = xr.open_mfdataset(\n",
        "                [str(item) for item in list(input_directory.glob('*.nc'))],\n",
        "                combine='by_coords')\n",
        "\n",
        "    if isinstance(output_directory, str):\n",
        "        output_directory = Path(output_directory)\n",
        "    try:\n",
        "        if not output_directory.exists():\n",
        "            output_directory.mkdir(parents=True)\n",
        "            print(f'[INFO] Directory successfully created : {output_directory}.')\n",
        "    except Exception as exception:\n",
        "        print(f\"[ERROR] Failed to create directory due to {str(exception)}.\")\n",
        "\n",
        "    ms_excel_row_limit = 1_048_576\n",
        "    space = '-' * 17\n",
        "    nb_grid_pts = reduce((lambda x, y: x * y),\n",
        "                         list([len(mds[c]) for c in mds.coords]))\n",
        "    if nb_grid_pts > ms_excel_row_limit:\n",
        "        print(f\"[INFO] The total number of rows for a single CSV file exceeds MS Excel limit.\")\n",
        "    \n",
        "    variable_name = list(mds.data_vars.keys())[0]\n",
        "    \n",
        "    try:\n",
        "        depth = len(mds.depth)\n",
        "        if max_depth_level is None:\n",
        "            depth = len(mds.depth)\n",
        "        elif max_depth_level < 0:\n",
        "            print(f\"[ERROR] Maximum depth level must be a positive index\"\n",
        "                  f\" from 0 to {len(mds.depth)}\")\n",
        "            return mfcsv\n",
        "        elif max_depth_level >= 0:\n",
        "            depth = max_depth_level\n",
        "        print(f\"[INFO] As a consequence, the total number of CSV files \"\n",
        "              f\"to be generated is: {len(mds.time) * (depth + 1)}\")\n",
        "\n",
        "        for t in range(len(mds.time)):\n",
        "            for d in range(len(mds.depth)):\n",
        "                if d > depth:\n",
        "                    break\n",
        "                DF = mds.isel(depth=d, time=t).to_dataframe()\n",
        "                if not DF[variable_name].dropna().empty:\n",
        "                    t_format = pd.to_datetime(str(DF['time'].values[0])).strftime(\"%Y%m%d\")\n",
        "                    v_format = '_'.join([DF[column].name for column in DF if column not in ['lon', 'lat', 'longitude', 'latitude', 'depth', 'time']])\n",
        "                    try:\n",
        "                        gb_format = '_'.join([str(len(mds[lonlat])) for lonlat in mds.coords if lonlat not in ['depth', 'time']])\n",
        "                    except Exception as exception:\n",
        "                        print(f\"[ERROR] Failed to set boundingbox: {str(exception)}\")\n",
        "                        output_filename = f'CMEMS-time_{t_format}-depth_{d}-{v_format}.csv'\n",
        "                    else:\n",
        "                        output_filename = f'CMEMS-gridbox_{gb_format}-time_{t_format}-depth_{d}-{v_format}.csv'\n",
        "                    finally:\n",
        "                        output_fpath = output_directory / output_filename\n",
        "                    if not output_fpath.exists():\n",
        "                        try:\n",
        "                            DF.dropna().to_csv(output_fpath)\n",
        "                        except Exception as exception:\n",
        "                            print(f\"[ERROR] Failed to write to disk: {repr(exception)}.\")\n",
        "                        else:\n",
        "                            msg = ''.join(\n",
        "                                (f\"[INFO] {space}\\n\", f\"[INFO-CSV] Output file :\"\n",
        "                                 f\" {output_fpath}\\n\",\n",
        "                                 f\"[INFO-CSV] File format : Comma-Separated Values\\n\",\n",
        "                                 f\"[INFO-CSV] Preview Stat:\\n {DF.dropna().describe()}\\n\",\n",
        "                                 f\"[INFO] {space}\"))\n",
        "                            print(''.join((\"[INFO] CONVERTING TO CSV\\n\", msg)))\n",
        "                    else:\n",
        "                        print(f\"[INFO] The CSV file {output_filename} already exists\"\n",
        "                              f\" in {output_directory.absolute()}.\")\n",
        "    except AttributeError:\n",
        "        print(\"[INFO] As a consequence, the total number of CSV files \"\n",
        "              f\"to be generated is: {len(mds.time)}\")\n",
        "        for t in range(len(mds.time)):\n",
        "            DF = mds.isel(time=t).to_dataframe()\n",
        "            if not DF[variable_name].dropna().empty:\n",
        "                t_format = pd.to_datetime(str(DF['time'].values[0])).strftime(\"%Y%m%d\")\n",
        "                v_format = '_'.join([DF[column].name for column in DF if column not in ['lon', 'lat', 'longitude', 'latitude', 'time']])\n",
        "                try:\n",
        "                    gb_format = '_'.join([str(len(mds[lonlat])) for lonlat in mds.coords if lonlat not in ['depth', 'time']])\n",
        "                except Exception as exception:\n",
        "                    print(f\"[ERROR] Failed to set boundingbox: {str(exception)}\")\n",
        "                    output_filename = f'CMEMS-time_{t_format}-{v_format}.csv'\n",
        "                else:\n",
        "                    output_filename = f'CMEMS-gridbox_{gb_format}-time_{t_format}-{v_format}.csv'\n",
        "                finally:\n",
        "                    output_fpath = output_directory / output_filename\n",
        "                if not output_fpath.exists():\n",
        "                    try:\n",
        "                        DF.dropna().to_csv(output_fpath)\n",
        "                    except Exception as exception:\n",
        "                        print(f\"[ERROR] Failed to write to disk: {repr(exception)}.\")\n",
        "                    else:\n",
        "                        msg = ''.join(\n",
        "                            (f\"[INFO] {space}\\n\", f\"[INFO-CSV] Output file :\"\n",
        "                             f\" {output_fpath}\\n\",\n",
        "                             f\"[INFO-CSV] File format : Comma-Separated Values\\n\",\n",
        "                             f\"[INFO-CSV] Preview Stat:\\n {DF.dropna().describe()}\\n\",\n",
        "                             f\"[INFO] {space}\"))\n",
        "                        print(''.join((\"[INFO] CONVERTING TO CSV\\n\", msg)))\n",
        "                else:\n",
        "                    print(f\"[INFO] The CSV file {output_filename} already exists\"\n",
        "                          f\" in {output_directory.absolute()}.\")\n",
        "    mfcsv = True\n",
        "    return mfcsv\n",
        "\n",
        "\n",
        "def to_nc4_csv(ncfiles, outputfile, skip_csv=False, default_nc_size=None):\n",
        "    \"\"\"\n",
        "    Convert file(s) to both netCDF-4 and csv files, based on computer limits.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ncfiles : TYPE\n",
        "        DESCRIPTION.\n",
        "    outputfile : TYPE\n",
        "        DESCRIPTION.\n",
        "    skip_csv : TYPE, optional\n",
        "        DESCRIPTION. The default is False.\n",
        "    default_nc_size : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    nc4 : bool\n",
        "        DESCRIPTION.\n",
        "    csv : bool\n",
        "        DESCRIPTION.\n",
        "    check_ow : bool\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "    nc4 = False\n",
        "    csv = False\n",
        "    if not default_nc_size:\n",
        "        default_nc_size = 16_000_000_000\n",
        "    mds_size = get_file_size(ncfiles)\n",
        "    check_fs = check_file_size(mds_size, default_nc_size)\n",
        "    check_ow = over_write(outputfile)\n",
        "    check_ow_csv = over_write(outputfile.with_suffix('.csv'))\n",
        "    if check_ow and check_fs:\n",
        "        with xr.open_mfdataset(ncfiles, combine='by_coords') as mds:\n",
        "            nc4 = to_nc4(mds, outputfile)\n",
        "    elif not check_ow:\n",
        "        print('[WARNING-NETCDF] Writing to disk action has been aborted by '\n",
        "              'user due to already existing file.')\n",
        "    elif not check_fs:\n",
        "        skip_csv = True\n",
        "    if check_ow_csv and not skip_csv:\n",
        "        with xr.open_mfdataset(ncfiles, combine='by_coords') as mds:\n",
        "            csv = to_csv(mds, outputfile)\n",
        "    return nc4, csv, check_ow\n",
        "\n",
        "\n",
        "def post_processing(outname,\n",
        "                    target_directory,\n",
        "                    target_out_directory=None,\n",
        "                    delete_files=True):\n",
        "    \"\"\"\n",
        "    Post-process the data already located on disk.\n",
        "\n",
        "    Concatenate a complete timerange in a single netCDF-4 file,\n",
        "    or if not possible, stack periods on minimum netCDF-4 files\n",
        "    (either by year or by month).\n",
        "    There is a possibility to delete old files to save space,\n",
        "    thanks to convertion from nc3 to nc4 and to convert to `CSV`,\n",
        "    if technically feasible.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    outname : TYPE\n",
        "        DESCRIPTION.\n",
        "    target_directory : TYPE\n",
        "        DESCRIPTION.\n",
        "    target_out_directory : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    delete_files : TYPE, optional\n",
        "        DESCRIPTION. The default is True.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    SystemExit\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    processing : bool\n",
        "        DESCRIPTION.\n",
        "\n",
        "    See Also\n",
        "    --------\n",
        "    get_file_pattern : called from this method\n",
        "    get_ncfiles : called from this method\n",
        "    get_years : called from this method\n",
        "    set_outputfile : called from this method\n",
        "    to_nc4_csv : called from this method\n",
        "    del_ncfiles : called from this method\n",
        "\n",
        "    \"\"\"\n",
        "    processing = False\n",
        "    try:\n",
        "        file_pattern = get_file_pattern(outname)\n",
        "    except AttributeError:\n",
        "        print(f'[ERROR] Program exits due to fatal error. There is no need '\n",
        "              'to re-run this script if no action has been taken from user side.')\n",
        "        raise SystemExit\n",
        "    sel_files = get_ncfiles(target_directory, file_pattern)\n",
        "    years = get_years(sel_files)\n",
        "    try:\n",
        "        single_outputfile = set_outputfile(file_pattern,\n",
        "                                           target_directory,\n",
        "                                           target_out_directory,\n",
        "                                           start_year=min(years),\n",
        "                                           end_year=max(years))\n",
        "    except ValueError as error:\n",
        "        print(\n",
        "            f'[ERROR] Processing failed due to no file matching pattern : {error}'\n",
        "        )\n",
        "    else:\n",
        "        nc4, csv, ow_choice = to_nc4_csv(sel_files, single_outputfile)\n",
        "        if not nc4 and not csv and ow_choice:\n",
        "            for year in years:\n",
        "                print(year)\n",
        "                ncfiles = get_ncfiles(target_directory, file_pattern, year)\n",
        "                outfilemerged = set_outputfile(file_pattern,\n",
        "                                               target_directory,\n",
        "                                               target_out_directory,\n",
        "                                               start_year=year)\n",
        "                nc4, csv, ow_choice = to_nc4_csv(ncfiles, outfilemerged)\n",
        "        if all([delete_files, nc4]):\n",
        "            del_ncfiles(sel_files)\n",
        "        processing = True\n",
        "    return processing\n",
        "\n",
        "\n",
        "def get(local_storage_directory=None,\n",
        "        target_out_directory=None,\n",
        "        view_myscript=None,\n",
        "        user=None,\n",
        "        pwd=None,\n",
        "        forcestack=False,\n",
        "        delete_files=True):\n",
        "    \"\"\"Download and post-process files to both compressed and tabular formats,\n",
        "    if applicable.\n",
        "\n",
        "    Download as many subsets of dataset required\n",
        "    to fulfill an initial data request based on a template command,\n",
        "    called ``VIEW SCRIPT`` generated by Copernicus Marine website\n",
        "    (https://marine.copernicus.eu).\n",
        "    Then, all files are post-processed locally.\n",
        "    e.g to concatenate in a single file, to save space (thanks to nc3 -> nc4),\n",
        "    to convert to ``CSV`` (if technically possible), and to delete old files.\n",
        "    End-user is guided throughout the process if no parameter is declared.\n",
        "    To get started, this function is the main entry point.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    local_storage_directory : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    target_out_directory : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    view_myscript : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    user : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    pwd : TYPE, optional\n",
        "        DESCRIPTION. The default is None.\n",
        "    forcestack : TYPE, optional\n",
        "        DESCRIPTION. The default is False.\n",
        "    delete_files : TYPE, optional\n",
        "        DESCRIPTION. The default is True.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    True.\n",
        "\n",
        "    See Also\n",
        "    --------\n",
        "    process_viewscript : Method to parse `VIEW SCRIPT`\n",
        "    post_processing : Method to convert downloaded data to other format\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    Ex 1. Let the user be guided by the script with interactive questions:\n",
        "\n",
        "    >>> cmemstb get\n",
        "\n",
        "    Ex 2. Get data matching a ``VIEW SCRIPT`` template command passed as `parameter`:\n",
        "\n",
        "    >>> cmemstb get --view_myscript=\"python -m motuclient --motu https://nrt.cmems-du.eu/motu-web/Motu --service-id GLOBAL_ANALYSIS_FORECAST_PHY_001_024-TDS --product-id global-analysis-forecast-phy-001-024 --longitude-min -20 --longitude-max 45 --latitude-min 25 --latitude-max 72 --date-min \\\\\"2019-08-18 12:00:00\\\\\" --date-max \\\\\"2020-08-31 12:00:00\\\\\" --depth-min 0.493 --depth-max 0.4942 --variable thetao --out-dir <OUTPUT_DIRECTORY> --out-name <OUTPUT_FILENAME> --user <USERNAME> --pwd <PASSWORD>\"\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    For Windows Operating System Users and when using the ``--view_myscript``\n",
        "    as parameter, you might want to double check that\n",
        "    ``double quote`` around dates are well escaped (see above example).\n",
        "    \"\"\"\n",
        "    target_directory = set_target_directory(local_storage_directory)\n",
        "    outname = process_viewscript(target_directory=target_directory,\n",
        "                                 view_myscript=view_myscript,\n",
        "                                 user=user,\n",
        "                                 pwd=pwd,\n",
        "                                 forcestack=forcestack)\n",
        "    post_processing(outname=outname,\n",
        "                    target_directory=target_directory,\n",
        "                    target_out_directory=target_out_directory,\n",
        "                    delete_files=delete_files)\n",
        "    return True\n",
        "\n",
        "\n",
        "def cli():\n",
        "    \"\"\"\n",
        "    Method to enable Command Line Interface and to expose only useful method for beginners.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None.\n",
        "\n",
        "    \"\"\"\n",
        "    fire.Fire({\n",
        "        'display_disk_stat': display_disk_stat,\n",
        "        'get': get,\n",
        "        'get_credentials': get_credentials,\n",
        "        'get_data': get_data,\n",
        "        'get_file_pattern': get_file_pattern,\n",
        "        'get_ncfiles': get_ncfiles,\n",
        "        'post_processing': post_processing,\n",
        "        'process_viewscript': process_viewscript,\n",
        "        'set_target_directory': set_target_directory,\n",
        "        'to_nc4_csv': to_nc4_csv,\n",
        "        'to_nc4': to_nc4,\n",
        "        'to_csv': to_csv,\n",
        "        'to_mfcsv': to_mfcsv\n",
        "    })\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Logging to: /content/log/CMEMS_API_20211106_1514.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9RgDOBnx-Ph"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}